{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가\n",
    "\n",
    "### 기존 개발 vs AI 개발\n",
    "- 기존 개발 : 유닛 테스트, E2E 테스트 -> QA (품질보증, Quality Assurance)\n",
    "- AI 개발 : 모델 평가 -> QA\n",
    "\n",
    "### 모델 학습 및 배포 과정\n",
    "- 데이터 취득 -> 모델 학습 -> 모델 평가 -> 모델 배포\n",
    "- 모델 평가\n",
    "  - 모델 검증\n",
    "  - 모델 성능 지표 분석\n",
    "  - 사용자 동작 테스트\n",
    "  - 모델 모니터링 (off line (online 되기 전), online의 경우 실제 배포 후 성능지표)\n",
    "\n",
    "### 모델 평가 과정\n",
    "- Model Validation (학습)\n",
    "- Model Evaluation\n",
    "  - 모델 출력 분포 다양한 매트릭으로 정밀 분석\n",
    "- Behavior Testing\n",
    "  - 시나리오 테스트\n",
    "  - 사용자 결과 테스트\n",
    "\n",
    "\n",
    "### 주요 평가 메트릭\n",
    "- 정확도 (Accuracy)\n",
    "- F1 Score\n",
    "  - 정밀도, 재현율 적절히 혼용\n",
    "  - 모델의 정확도가 높더라도 샘플수가 적어서 편향될 수 있다.\n",
    "- 정밀도 (Precision)\n",
    "- 재현율 (Recall)\n",
    "  - 모델 평가한 것 중 제대로 맞는 비율은?\n",
    "  - 잘못 예측한 Positive를 줄이는 것이 목적\n",
    "- 분류 성능 평가 지표\n",
    "  - 실제 Positive 데이터 중 모델이 맞춘 비율은 어느정도?\n",
    "  - 모델이 Positive 놓치는 것이 없도록 집중\n",
    "- 드리프트 (Drift)\n",
    "  - 모델이 잘 학습되었다 하더라도 실제 분포와 다를 수 있는데, 이 차이를 드리프트(Drift)라고 부른다.\n",
    "\n",
    "## 분류 모델 학습 및 평가 실습\n",
    "\n",
    "### 분류 모델\n",
    "- 뉴스 카테고리 분류\n",
    "- 과정\n",
    "  - AG News 입력 -> BertForSequenceClassification -> 0 World, 1 Sports, 2 Business, 3 Sci/Tech\n",
    "- BertForSequenceClassification\n",
    "  - Bert는 경량데이터, 12만개중에서 1200개만 학습 돌릴 예정\n",
    "- huggingface\n",
    "  - 모델 및 데이터 등록 사이트 (GitHub와 비슷)\n",
    "\n",
    "### 시나리오\n",
    "\n",
    "```mermaid\n",
    "A_1[\"데이터 셋 전처리\"]-->B[\"모델 학습\"]-->C[\"모델 평가\"]\n",
    "A_2[\"BERT 모델 다운로드\"]-->B\n",
    "C-->C_1[\"Accuracy 평가\"]\n",
    "C-->C_2[\"Precision, Recall, F1 Score 평가\"]\n",
    "C-->C_3[\"Confusion Matrix 평가\"]\n",
    "C-->C_4[\"ROC Curve 평가\"]\n",
    "```\n",
    "- ROC Curve\n",
    "  - Threshold에 따라 True Positive Rate(TPR)와 False Positive Rate(FPR)을 바탕으로 나타낸 모델 성능 그래프\n",
    "  - 그래프 밑면의 넓이가 넓을 수록 모델 성능이 좋음\n",
    "  - 대각선은 랜덤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "%conda install transformers\n",
    "%pip install -U scikit-learn\n",
    "# %pip install -U scikit-image\n",
    "%pip install -U matplotlib\n",
    "%conda install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from typing import TypedDict\n",
    "\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, precision_recall_fscore_support, roc_curve\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TypedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDatasetItem\u001b[39;00m(TypedDict):\n\u001b[1;32m      2\u001b[0m     text:\u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m      3\u001b[0m     label:\u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TypedDict' is not defined"
     ]
    }
   ],
   "source": [
    "class DatasetItem(TypedDict):\n",
    "    text:str\n",
    "    label:str\n",
    "\n",
    "def preprocess_data(dataset_item: DatasetItem) -> dict[str, torch.Tensor]:\n",
    "    return tokenizer(dataset_item[\"text\"], truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "train_dataset = dataset[\"train\"].slect(range(1200)).map(preprocess_data, batched=True)\n",
    "test_dataset = dataset[\"test\"].slect(range(800)).map(preprocess_data, batched=True)\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
